# 多线程（java.util.concurrent

## 线程

1. 进程：程序的一次执行过程，是系统运行程序的基本单位
2. 线程：比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程
3. Java 线程和操作系统线程：现在的 Java 线程的本质其实就是操作系统的线程
4. 线程与进程：
    - 线程是进程划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。
    - 线程执行开销小，但不利于资源的管理和保护；而进程正相反
5. 创建线程
    - 严格来说，Java 就只有一种方式可以创建线程，那就是通过new Thread().start()创建
    - 一般来说，创建线程有很多种方式，例如**继承Thread类**、**实现Runnable接口**、**实现Callable接口**、使用线程池、使用CompletableFuture类等等

6. 线程生命周期和状态
    - NEW: 初始状态，线程被创建出来但没有被调用 start() 。
    - RUNNABLE: 运行状态，线程被调用了 start()等待运行的状态。
        - *操作系统层面*
        - READY
        - RUNNING
    - BLOCKED：阻塞状态，需要等待锁释放。
    - WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。
    - TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。
    - TERMINATED：终止状态，表示该线程已经运行完毕。

7. 线程上下文切换
8. Thread#sleep() 方法和 Object#wait() 方法对比
9. 可以直接调用 Thread 类的 run 方法吗？
    - 调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。

## 多线程

1. 线程调度方式
    - 抢占式调度（Preemptive Scheduling）：操作系统决定何时暂停当前正在运行的线程，并切换到另一个线程执行。这种切换通常是由系统时钟中断（时间片轮转）或其他高优先级事件（如 I/O 操作完成）触发的。这种方式存在上下文切换开销，但公平性和 CPU 资源利用率较好，不易阻塞。
    - 协同式调度（Cooperative Scheduling）：线程执行完毕后，主动通知系统切换到另一个线程。这种方式可以减少上下文切换带来的性能开销，但公平性较差，容易阻塞。
2. 两种类型线程
    - CPU 密集型：CPU 密集型的线程主要进行计算和逻辑处理，需要占用大量的 CPU 资源。
    - IO 密集型：IO 密集型的线程主要进行输入输出操作，如读写文件、网络通信等，需要等待 IO 设备的响应，而不占用太多的 CPU 资源。

## 死锁

## 虚拟线程

1. 定义：虚拟线程（Virtual Thread）是 JDK 而不是 OS 实现的轻量级线程（Lightweight Process，LWP），由 JVM 调度。许多虚拟线程共享同一个操作系统线程，虚拟线程的数量可以远大于操作系统线程的数量。

## Java内存模型（JMM（Java Memory Model

1. 定义：
    - Java虚拟机规范的一部分，定义了Java程序中多线程之间如何通过内存进行交互，描述了变量的读取和写入操作如何在不同线程之间进行可见性和有序性。
    - 对于一个共享变量，当另一个线程对这个共享变量执行写操作后，这个线程对这个共享变量的可见性。
    - Java 定义的并发编程相关的一组规范，除了抽象了线程和主内存之间的关系之外，其还规定了从 Java 源代码到 CPU 可执行指令的这个转化过程要遵守哪些和并发相关的原则和规范，其主要目的是为了简化多线程编程，增强程序可移植性的。

2. CPU缓存模型：为了解决 CPU 处理速度和内存处理速度不对等的问题
    - CPU Cache 缓存的是内存数据，用于解决 CPU 处理速度和内存不匹配的问题。内存缓存的是硬盘数据，用于解决硬盘访问速度过慢的问题。
    - 内存缓存不一致性的问题：制定缓存一致协议
3. 指令重排序
    - 编译器优化重排：编译器（包括 JVM、JIT 编译器等）在不改变单线程程序语义的前提下，重新安排语句的执行顺序。
    - 指令并行重排：现代处理器采用了指令级并行技术(Instruction-Level Parallelism，ILP)来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。

4. JMM 是如何抽象线程和主内存之间的关系？
    - Java 内存模型（JMM） 抽象了线程和主内存之间的关系，就比如说线程之间的共享变量必须存储在主内存中。
    - 主内存：所有线程创建的实例对象都存放在主内存中，不管该实例对象是成员变量，还是局部变量，类信息、常量、静态变量都是放在主内存中。为了获取更好的运行速度，虚拟机及硬件系统可能会让工作内存优先存储于寄存器和高速缓存中。
    - 本地内存：每个线程都有一个私有的本地内存，本地内存存储了该线程以读 / 写共享变量的副本。每个线程只能操作自己本地内存中的变量，无法直接访问其他线程的本地内存。如果线程间需要通信，必须通过主内存来进行。本地内存是 JMM 抽象出来的一个概念，并不真实存在，它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。

5. Java 内存区域和 JMM 有何区别？
    - JVM 内存区域和 Java 虚拟机的运行时区域相关，定义了 JVM 在运行时如何分区存储程序数据，就比如说堆主要用于存放对象实例。Java 内存模型和 Java 的并发编程相关，抽象了线程和主内存之间的关系就比如说线程之间的共享变量必须存储在主内存中，规定了从 Java 源代码到 CPU 可执行指令的这个转化过程要遵守哪些和并发相关的原则和规范，其主要目的是为了简化多线程编程，增强程序可移植性的。

6. happens-before 原则是什么？
    - 为了对编译器和处理器的约束尽可能少，只要不改变程序的执行结果（单线程程序和正确执行的多线程程序），编译器和处理器怎么进行重排序优化都行。
    - 对于会改变程序执行结果的重排序，JMM 要求编译器和处理器必须禁止这种重排序。
7. 为什么需要 happens-before 原则？
    - happens-before 原则的诞生是为了程序员和编译器、处理器之间的平衡。程序员追求的是易于理解和编程的强内存模型，遵守既定规则编码即可。编译器和处理器追求的是较少约束的弱内存模型，让它们尽己所能地去优化性能，让性能最大化

8. 并发三个重要特性
    - 原子性
    - 可见性
    - 有序性

## volatile
- 保证了变量的可见性，以及防止指令重排序（双重校验锁单例

## 乐观锁与悲观锁

1. 悲观锁
    - 悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题(比如共享数据被修改)，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。也就是说，共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。
    - Java 中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现
2. 乐观锁
    - 乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改了（具体方法可以使用版本号机制或 CAS 算法）。
    - Java 中java.util.concurrent.atomic包下面的原子变量类（比如AtomicInteger、LongAdder）就是使用了乐观锁的一种实现方式 CAS 实现的。

3. synchronized关键字：可重入、独占式、不可中断的锁
    1. 用法：
        - 修饰实例方法（锁当前对象实例）：给当前对象实例加锁，进入同步代码前要获得 当前对象实例的锁 
        - 修饰静态方法（锁当前类）：给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得 当前 class 的锁。
        - 修饰代码块（锁指定对象/类）：
            - synchronized(object) 表示进入同步代码库前要获得 给定对象的锁。
            - synchronized(类.class) 表示进入同步代码前要获得 给定 Class 的锁

    2. 优化：
        - 在 Java 6 之后， synchronized 引入了大量的优化如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销，这些优化让 synchronized 锁的效率提升了很多（JDK18 中，偏向锁已经被彻底废弃，前面已经提到过了）
        - 锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。

4. ReentrantLock：可重入、独占式、可中断的锁（AQS
    1. 定义： 
        - 实现了 Lock 接口，是一个可重入且独占式的锁，和 synchronized 关键字类似。不过，ReentrantLock 更灵活、更强大，增加了轮询、超时、中断、公平锁和非公平锁等高级功能。
        - ReentrantLock 里面有一个内部类 Sync，Sync 继承 AQS（AbstractQueuedSynchronizer），添加锁和释放锁的大部分操作实际上都是在 Sync 中实现的。Sync 有公平锁 FairSync 和非公平锁 NonfairSync 两个子类。默认使用非公平锁。

5. ReentrantReadWriteLock
    1. 定义：
        - ReentrantReadWriteLock 实现了 ReadWriteLock ，是一个可重入的读写锁，既可以保证多个线程同时读的效率，同时又可以保证有写入操作时的线程安全。
        - ReentrantReadWriteLock 其实是两把锁，一把是 WriteLock (写锁)，一把是 ReadLock（读锁） 。读锁是共享锁，写锁是独占锁。读锁可以被同时读，可以同时被多个线程持有，而写锁最多只能同时被一个线程持有。默认使用非公平锁。

6. StampedLock

## ThreadLocal
1. 作用：如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是ThreadLocal变量名的由来。他们可以使用 get() 和 set() 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题
2. 原理：最终的变量是放在了当前线程的 ThreadLocalMap 中，并不是存在 ThreadLocal 上，ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。 ThrealLocal 类中可以通过Thread.currentThread()获取到当前线程对象后，直接通过getMap(Thread t)可以访问到该线程的ThreadLocalMap对象。每个Thread中都具备一个ThreadLocalMap，而ThreadLocalMap可以存储以ThreadLocal为 key ，Object 对象为 value 的键值对。

3. 内存泄漏问题：

## 线程池
1. 定义：线程池就是管理一系列线程的资源池。当有任务要处理时，直接从线程池中获取线程来处理，处理完之后线程并不会立即被销毁，而是等待下一个任务。
2. 作用：
    - 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
    - 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。
    - 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。
3. 方式：
    - 通过ThreadPoolExecutor构造函数来创建（推荐
    - 通过Executor框架的工具类Executors来创建
        - FixedThreadPool：固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。
        - SingleThreadExecutor： 只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。
        - CachedThreadPool： 可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。
        - ScheduledThreadPool：给定的延迟后运行任务或者定期执行任务的线程池
4. 常见参数
    - ThreadPoolExecutor 3 个最重要的参数：
        - corePoolSize : 任务队列未达到队列容量时，最大可以同时运行的线程数量。
        - maximumPoolSize : 任务队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
        - workQueue: 新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。
    - ThreadPoolExecutor其他常见参数 :
        - keepAliveTime:线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁。
        - unit : keepAliveTime 参数的时间单位。
        - threadFactory :executor 创建新线程的时候会用到。
        - handler :拒绝策略（后面会单独详细介绍一下）。

5. 拒绝策略
    - ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。
    - ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果你的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。
    - ThreadPoolExecutor.DiscardPolicy：不处理新任务，直接丢弃掉。
    - ThreadPoolExecutor.DiscardOldestPolicy：此策略将丢弃最早的未处理的任务请求。

6. 线程池处理任务流程
    - 如果当前运行的线程数小于核心线程数，那么就会新建一个线程来执行任务。
    - 如果当前运行的线程数等于或大于核心线程数，但是小于最大线程数，那么就把该任务放入到任务队列里等待执行。
    - 如果向任务队列投放任务失败（任务队列已经满了），但是当前运行的线程数是小于最大线程数的，就新建一个线程来执行任务。
    - 如果当前运行的线程数已经等同于最大线程数了，新建线程将会使当前运行的线程超出最大线程数，那么当前任务会被拒绝，拒绝策略会调用RejectedExecutionHandler.rejectedExecution()方法。

7. 如何设定线程池大小
    - CPU 密集型任务(N+1)： 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1。比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。
    - I/O 密集型任务(2N)： 这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。

8. Future
9. CompletableFuture

10. Executor框架
    1. 三大部分组成
        - 任务(Runnable /Callable)
        - 任务的执行(Executor)
        - 异步计算的结果(Future)
    2. 使用流程
        - 主线程首先要创建实现 Runnable 或者 Callable 接口的任务对象。
        - 把创建完成的实现 Runnable/Callable接口的 对象直接交给 ExecutorService 执行: ExecutorService.execute（Runnable command））或者也可以把 Runnable 对象或Callable 对象提交给 ExecutorService 执行（ExecutorService.submit（Runnable task）或 ExecutorService.submit（Callable <T> task））。
        - 如果执行 ExecutorService.submit（…），ExecutorService 将返回一个实现Future接口的对象（我们刚刚也提到过了执行 execute()方法和 submit()方法的区别，submit()会返回一个 FutureTask 对象）。由于 FutureTask 实现了 Runnable，我们也可以创建 FutureTask，然后直接交给 ExecutorService 执行。
        - 最后，主线程可以执行 FutureTask.get()方法来等待任务执行完成。主线程也可以执行 FutureTask.cancel（boolean mayInterruptIfRunning）来取消此任务的执行

11. 常用阻塞队列
    1. LinkedBlockingQueue（无界队列）：容量为 Integer.MAX_VALUE。FixedThreadPool 和 SingleThreadExector 。FixedThreadPool最多只能创建核心线程数的线程（核心线程数和最大线程数相等），SingleThreadExector只能创建一个线程（核心线程数和最大线程数都是 1），二者的任务队列永远不会被放满。
    2. SynchronousQueue（同步队列）：CachedThreadPool 。SynchronousQueue 没有容量，不存储元素，目的是保证对于提交的任务，如果有空闲线程，则使用空闲线程来处理；否则新建一个线程来处理任务。也就是说，CachedThreadPool 的最大线程数是 Integer.MAX_VALUE ，可以理解为线程数是可以无限扩展的，可能会创建大量线程，从而导致 OOM。
    3. DelayedWorkQueue（延迟阻塞队列）：ScheduledThreadPool 和 SingleThreadScheduledExecutor 。DelayedWorkQueue 的内部元素并不是按照放入的时间排序，而是会按照延迟的时间长短对任务进行排序，内部采用的是“堆”的数据结构，可以保证每次出队的任务都是当前队列中执行时间最靠前的。DelayedWorkQueue 添加元素满了之后会自动扩容原来容量的 1/2，即永远不会阻塞，最大扩容可达 Integer.MAX_VALUE，所以最多只能创建核心线程数的线程
        

## AQS
1. 定义：AQS 的全称为 AbstractQueuedSynchronizer，是一个抽象类，主要用来构建锁和同步器
2. 原理：
3. Semaphore
4. CountDownLatch
5. CyclicBarrier

## CAS
1. 在 Java 中，实现 CAS（Compare-And-Swap, 比较并交换）操作的一个关键类是Unsafe

## 常见并发容器

1. ConcurrentHashMap
2. CopyOnWriteArrayList
3. ConcurrentLinkedQueue
4. BlockingQueue
5. ConcurrentSkipListMap

## Atomic原子类

## 杂
1. Synchronized
    原子性：确保线程互斥地访问同步代码；
    可见性：保证共享变量的修改能够及时可见，其实是通过Java内存模型中的“对一个变量unlock操作之前，必须要同步到主内存中；如果对一个变量进行lock操作，则将会清空工作内存中此变量的值，在执行引擎使用此变量前，需要重新从主内存中load操作或assign操作初始化变量值” 来保证的；
    有序性：有效解决重排序问题，即 “一个unlock操作先行发生(happen-before)于后面对同一个锁的lock操作”；

    修饰实例方法：作用于当前实例加锁
    修饰静态方法：作用于当前类对象加锁
    修饰代码块：指定加锁对象，对给定对象加锁，每个对象一个锁

    无论synchronized关键字加在方法上还是对象上，如果它作用的对象是非静态的，则它取得的锁是对象；如果synchronized作用的对象是一个静态方法或一个类，则它取得的锁是对类，该类所有的对象同一把锁。 
    每个对象只有一个锁（lock）与之相关联，谁拿到这个锁谁就可以运行它所控制的那段代码。 
    实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制。

2. ReentrantLock
    lock.lock();
    lock.unlock();

3. volatile（保证线程可见性，禁止指令重排序）
    volatile修饰符适用于以下场景：某个属性被多个线程共享，其中有一个线程修改了此属性，其他线程可以立即得到修改后的值，比如booleanflag;或者作为触发器，实现轻量级同步。
    volatile属性的读写操作都是无锁的，它不能替代synchronized，因为它没有提供原子性和互斥性。因为无锁，不需要花费时间在获取锁和释放锁_上，所以说它是低成本的。
    volatile只能作用于属性，我们用volatile修饰属性，这样compilers就不会对这个属性做指令重排序。
    volatile提供了可见性，任何一个线程对其的修改将立马对其他线程可见，volatile属性不会被线程缓存，始终从主 存中读取。
    volatile提供了happens-before保证，对volatile变量v的写入happens-before所有其他线程后续对v的读操作。
    volatile可以使得long和double的赋值是原子的。
    volatile可以在单例双重检查中实现可见性和禁止指令重排序，从而保证安全性